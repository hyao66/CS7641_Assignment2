{"cells":[{"cell_type":"markdown","id":"daaded0e","metadata":{"id":"daaded0e"},"source":["# Assignment 2 - Randomized Optimization - Part II\n","## student: hyao66"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"NiCw-ZKUPxKy"},"id":"NiCw-ZKUPxKy","execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install mlrose"],"metadata":{"id":"WiXTNRC1QFc-"},"id":"WiXTNRC1QFc-","execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install mlrose-hiive"],"metadata":{"id":"dbMELW_wktWW"},"id":"dbMELW_wktWW","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"470dffb7","metadata":{"id":"470dffb7"},"outputs":[],"source":["# import library\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import six\n","import sys\n","sys.modules['sklearn.externals.six'] = six\n","\n","import mlrose\n","import mlrose_hiive\n","import time\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn import preprocessing\n","from sklearn.preprocessing import OneHotEncoder, LabelEncoder, MinMaxScaler\n","from sklearn import metrics\n","# from yellowbrick.model_selection import LearningCurve, learning_curve\n","from sklearn.model_selection import StratifiedKFold\n","import seaborn as sns"]},{"cell_type":"markdown","id":"d7a75cf4","metadata":{"id":"d7a75cf4"},"source":["## part II: apply gd, rhc, sa and ga to NN"]},{"cell_type":"code","execution_count":null,"id":"9be8abcc","metadata":{"id":"9be8abcc"},"outputs":[],"source":["## load and process data\n","\n","raw = pd.read_csv('/content/drive/MyDrive/CS7641A2/customer_segmentation.csv', index_col = 'ID')\n","\n","# label encoding for categorical data\n","raw['Gender'].astype('category')\n","raw['Ever_Married'].astype('category')\n","raw['Graduated'].astype('category')\n","raw['Profession'].astype('category')\n","raw['Spending_Score'].astype('category')\n","raw['Var_1'].astype('category')\n","raw['Segmentation'].astype('category')\n","le = preprocessing.LabelEncoder()\n","raw['Gender_Cat'] = le.fit_transform(raw['Gender'])\n","raw['Ever_Married_Cat'] = le.fit_transform(raw['Ever_Married'])\n","raw['Graduated_Cat'] = le.fit_transform(raw['Graduated'])\n","raw['Profession_Cat'] = le.fit_transform(raw['Profession'])\n","raw['Spending_Score_Cat'] = le.fit_transform(raw['Spending_Score'])\n","raw['Var_1_Cat'] = le.fit_transform(raw['Var_1'])\n","raw['Segmentation_Cat'] = le.fit_transform(raw['Segmentation'])\n","\n","raw = raw.dropna()\n","\n","\n","# train test split\n","# split data into training and testing sets\n","# Split the data into training and testing sets\n","raw_cat = raw.drop([\"Gender\",\"Ever_Married\",\"Graduated\",\"Profession\",\"Spending_Score\",\"Var_1\",\"Segmentation\"], axis = 1)\n","\n","\n","features = raw_cat.drop(['Segmentation_Cat'], axis = 1)\n","feature_list = list(features.columns)\n","features_np = np.array(features)\n","\n","labels = raw_cat[['Segmentation_Cat']]\n","labels_np = np.array(labels)[:,0]\n","\n","label_unique = list(set(labels_np))\n","\n","train_features, test_features, train_labels, test_labels = train_test_split(features_np, labels_np, test_size = 0.20, \n","                                                                            random_state = 42)\n","\n","print(feature_list)\n","print('Training Features Shape:', train_features.shape)\n","print('Training Labels Shape:', train_labels.shape)\n","print('Testing Features Shape:', test_features.shape)\n","print('Testing Labels Shape:', test_labels.shape)\n","\n","\n","# One hot encode target values\n","one_hot = OneHotEncoder()\n","\n","train_labels_onehot = one_hot.fit_transform(train_labels.reshape(-1, 1)).todense()\n","test_labels_onehot = one_hot.transform(test_labels.reshape(-1, 1)).todense()\n","\n","\n","label = LabelEncoder()\n","train_labels_label = label.fit_transform(train_labels)\n","test_labels_label = label.fit_transform(test_labels)\n","\n","# normalize x\n","scaler = MinMaxScaler()\n","\n","train_features = scaler.fit_transform(train_features)\n","test_features = scaler.transform(test_features)"]},{"cell_type":"code","execution_count":null,"id":"576cbeec","metadata":{"id":"576cbeec"},"outputs":[],"source":["##########\n","#Back Prop\n","##########\n","clf = mlrose.NeuralNetwork(hidden_nodes=[100,100,50,50], activation='sigmoid',\n","                           algorithm = 'gradient_descent',early_stopping = False, \n","                           max_attempts = 100, max_iters = 2500, clip_max = 5,\n","                           bias = True, learning_rate = 0.00001,\n","                           curve = True, random_state=42)\n","\n","start_time = time.time()\n","clf.fit(train_features, train_labels_onehot)\n","end_time = time.time()\n","base_time = end_time-start_time\n","y_pred = clf.predict(test_features)\n","gd_score = metrics.accuracy_score(test_labels_onehot, y_pred)\n","gd_fitness_curve = clf.fitness_curve\n","\n","print('train time:', base_time)\n","print('accuracy:', gd_score)"]},{"cell_type":"code","source":["gd_fitness_curve"],"metadata":{"id":"WAko80D8JW_u"},"id":"WAko80D8JW_u","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"10f8d930","metadata":{"id":"10f8d930"},"outputs":[],"source":["print('train time:', base_time)\n","print('accuracy:', gd_score)\n","\n","plt.figure()\n","\n","plt.plot(gd_fitness_curve)\n","plt.xlabel(\"Iterations\")\n","plt.ylabel(\"Negative Loss\")\n","plt.title('Fitness curve for NN with gradient descent')"]},{"cell_type":"code","source":["\n","gd_fitness_curve = [ -x for x in gd_fitness_curve]\n","\n","plt.figure()\n","\n","plt.plot(gd_fitness_curve)\n","plt.xlabel(\"Iterations\")\n","plt.ylabel(\"Loss\")\n","plt.title('Loss curve for NN with gradient descent')"],"metadata":{"id":"wcmZ_xyz5HmP"},"id":"wcmZ_xyz5HmP","execution_count":null,"outputs":[]},{"cell_type":"code","source":["results = []\n","for i in range(1, 2601, 100):\n","        clf = mlrose.NeuralNetwork(hidden_nodes=[100,100,50,50], activation='sigmoid',\n","                                   algorithm ='gradient_descent',early_stopping = False, \n","                                   max_attempts = 100, max_iters = i, clip_max = 5,\n","                                   bias = True, learning_rate = 0.00001,\n","                                   curve = False, random_state=42)\n","        clf.fit(train_features, train_labels_onehot)\n","        y_train_pred = clf.predict(train_features)\n","        y_train_accuracy = metrics.accuracy_score(train_labels_onehot, y_train_pred)\n","\n","        y_pred = clf.predict(test_features)\n","        y_test_accuracy = metrics.accuracy_score(test_labels_onehot, y_pred)\n","\n","        results.append([i, 'gradient_descent', y_train_accuracy, y_test_accuracy])\n","        print([i, 'gradient_descent', y_train_accuracy, y_test_accuracy])\n","        "],"metadata":{"id":"5EThEt2iRg3s"},"id":"5EThEt2iRg3s","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# plot learning curve\n","df = pd.DataFrame(results, columns=[\"Iterations\", \"Algorithm\", \"Train_Accuracy\", \"Test_Accuracy\"])"],"metadata":{"id":"lGuefvBPTZvG"},"id":"lGuefvBPTZvG","execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure()\n","plt.plot(df['Iterations'], df['Train_Accuracy'], marker='o')\n","plt.ylabel('Accuracy')\n","plt.title('Neural Net experiments on Gradient Descent')\n","plt.plot(df['Iterations'], df['Test_Accuracy'], marker='d')\n","plt.xlabel('Iterations')\n","plt.legend(['train', 'test'])"],"metadata":{"id":"24jGTOcvnuCw"},"id":"24jGTOcvnuCw","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##########\n","#RHC\n","##########\n","\n","clf = mlrose.NeuralNetwork(hidden_nodes=[100,100,50,50], activation='sigmoid',\n","                           algorithm = 'random_hill_climb',early_stopping = False, \n","                           max_attempts = 100, max_iters = 2500, clip_max = 5,\n","                           bias = True, learning_rate = 0.1,\n","                           curve = True, random_state=42)\n","start_time = time.time()\n","clf.fit(train_features, train_labels_onehot)\n","end_time = time.time()\n","rhc_time = end_time-start_time\n","y_pred = clf.predict(test_features)\n","rhc_score = metrics.accuracy_score(test_labels_onehot, y_pred)\n","rhc_fitness_curve = clf.fitness_curve\n","\n","print('train time:', rhc_time)\n","print('accuracy:', rhc_score)\n","\n"],"metadata":{"id":"FaLXWMEtlGnX"},"id":"FaLXWMEtlGnX","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##########\n","#RHC\n","##########\n","\n","clf = mlrose.NeuralNetwork(hidden_nodes=[100,100,50,50], activation='sigmoid',\n","                           algorithm = 'random_hill_climb',early_stopping = False, \n","                           max_attempts = 1000000, max_iters = 1, clip_max = 5,\n","                           bias = True, learning_rate = 1,\n","                           curve = True, random_state=42)\n","start_time = time.time()\n","clf.fit(train_features, train_labels_onehot)\n","end_time = time.time()\n","rhc_time = end_time-start_time\n","y_pred = clf.predict(test_features)\n","rhc_score = metrics.accuracy_score(test_labels_onehot, y_pred)\n","rhc_fitness_curve = clf.fitness_curve\n","\n","print('train time:', rhc_time)\n","print('accuracy:', rhc_score)"],"metadata":{"id":"G-7xSfX79J7G"},"id":"G-7xSfX79J7G","execution_count":null,"outputs":[]},{"cell_type":"code","source":["rhc_fitness_curve = [ -x for x in rhc_fitness_curve]\n","\n","plt.figure()\n","\n","plt.plot(rhc_fitness_curve)\n","plt.xlabel(\"Iterations\")\n","plt.ylabel(\"Loss\")\n","plt.title('Loss curve for NN with RHC')"],"metadata":{"id":"yTDeLzRzq8kx"},"id":"yTDeLzRzq8kx","execution_count":null,"outputs":[]},{"cell_type":"code","source":["rhc_fitness_curve[-10:]"],"metadata":{"id":"rntuPeBvEgCN"},"id":"rntuPeBvEgCN","execution_count":null,"outputs":[]},{"cell_type":"code","source":["results = []\n","\n","for i in range(1, 2601, 100):\n","        clf = mlrose.NeuralNetwork(hidden_nodes=[100,100,50,50], activation='sigmoid',\n","                                   algorithm ='random_hill_climb',early_stopping = False, \n","                                   max_attempts = 100, max_iters = i, clip_max = 5,\n","                                   bias = True, learning_rate = 0.1,\n","                                   curve = False, random_state=42)\n","        clf.fit(train_features, train_labels_onehot)\n","        y_train_pred = clf.predict(train_features)\n","        y_train_accuracy = metrics.accuracy_score(train_labels_onehot, y_train_pred)\n","\n","        y_pred = clf.predict(test_features)\n","        y_test_accuracy = metrics.accuracy_score(test_labels_onehot, y_pred)\n","\n","        results.append([i, 'random_hill_climb', y_train_accuracy, y_test_accuracy])\n","        print([i, 'random_hill_climb', y_train_accuracy, y_test_accuracy])"],"metadata":{"id":"dAXiA7lG52_H"},"id":"dAXiA7lG52_H","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# plot learning curve\n","df = pd.DataFrame(results, columns=[\"Iterations\", \"Algorithm\", \"Train_Accuracy\", \"Test_Accuracy\"])\n","plt.figure()\n","plt.plot(df['Iterations'], df['Train_Accuracy'], marker='o')\n","plt.ylabel('Accuracy')\n","plt.title('Neural Net experiments on Random hill climbing')\n","plt.plot(df['Iterations'], df['Test_Accuracy'], marker='d')\n","plt.xlabel('Iterations')\n","plt.legend(['train', 'test'])"],"metadata":{"id":"i-bqTKTx7FM5"},"id":"i-bqTKTx7FM5","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##########\n","#SA\n","##########\n","\n","clf = mlrose.NeuralNetwork(hidden_nodes=[100,100,50,50], activation='sigmoid',\n","                           algorithm = 'simulated_annealing',early_stopping = False, \n","                           max_attempts = 100, max_iters = 2500, clip_max = 5,\n","                           bias = True, learning_rate = 0.1,schedule=mlrose.GeomDecay(init_temp = 100, decay=0.1, min_temp=1),\n","                           curve = True, random_state=1)\n","start_time = time.time()\n","clf.fit(train_features, train_labels_onehot)\n","end_time = time.time()\n","sa_time = end_time-start_time\n","y_pred = clf.predict(test_features)\n","sa_score = metrics.accuracy_score(test_labels_onehot, y_pred)\n","sa_fitness_curve = clf.fitness_curve\n","\n","print('train time:', sa_time)\n","print('accuracy:', sa_score)\n","\n"],"metadata":{"id":"Ng_WJ8moykhQ"},"id":"Ng_WJ8moykhQ","execution_count":null,"outputs":[]},{"cell_type":"code","source":["sa_fitness_curve = [ -x for x in sa_fitness_curve]\n","\n","plt.figure()\n","\n","plt.plot(sa_fitness_curve)\n","plt.xlabel(\"Iterations\")\n","plt.ylabel(\"Loss\")\n","plt.title('Loss curve for NN with SA')"],"metadata":{"id":"pN81YHYjGuPZ"},"id":"pN81YHYjGuPZ","execution_count":null,"outputs":[]},{"cell_type":"code","source":["results = []\n","\n","\n","for i in range(1, 2601, 100):\n","        clf = mlrose.NeuralNetwork(hidden_nodes=[100,100,50,50], activation='sigmoid',\n","                                   algorithm ='simulated_annealing',early_stopping = False, \n","                                   max_attempts = 100, max_iters = i, clip_max = 5,\n","                                   bias = True, learning_rate = 0.1,schedule=mlrose.GeomDecay(init_temp = 100, decay=0.1, min_temp=1),\n","                                   curve = False, random_state=1)\n","        clf.fit(train_features, train_labels_onehot)\n","        y_train_pred = clf.predict(train_features)\n","        y_train_accuracy = metrics.accuracy_score(train_labels_onehot, y_train_pred)\n","\n","        y_pred = clf.predict(test_features)\n","        y_test_accuracy = metrics.accuracy_score(test_labels_onehot, y_pred)\n","\n","        results.append([i, 'simulated_annealing', y_train_accuracy, y_test_accuracy])\n","        print([i, 'simulated_annealing', y_train_accuracy, y_test_accuracy])"],"metadata":{"id":"bgUNvHYUGyRc"},"id":"bgUNvHYUGyRc","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# plot learning curve\n","df = pd.DataFrame(results, columns=[\"Iterations\", \"Algorithm\", \"Train_Accuracy\", \"Test_Accuracy\"])\n","plt.figure()\n","plt.plot(df['Iterations'], df['Train_Accuracy'], marker='o')\n","plt.ylabel('Accuracy')\n","plt.title('Neural Net experiments on simulated annealing')\n","plt.plot(df['Iterations'], df['Test_Accuracy'], marker='d')\n","plt.xlabel('Iterations')\n","plt.legend(['train', 'test'])"],"metadata":{"id":"CN54GhmTG_nI"},"id":"CN54GhmTG_nI","execution_count":null,"outputs":[]},{"cell_type":"code","source":["## tune GA \n","results = []\n","\n","# max_attempts = 100\n","max_iters = 5\n","\n","max_attempts_list = [100, 500, 1000, 5000]\n","pop_size_list = [100, 200, 500]\n","mutation_prob_list = [0.001, 0.005, 0.01, 0.05, 0.1]\n","\n","# run generic algorithm\n","for pop in pop_size_list:\n","  for mutation in mutation_prob_list:\n","    for max_attempt in max_attempts_list:\n","        clf = mlrose.NeuralNetwork(hidden_nodes=[100,100,50,50], activation='sigmoid',\n","                                  algorithm = 'genetic_alg',early_stopping = False, \n","                                  max_attempts = max_attempt, max_iters = max_iters, clip_max = 5,\n","                                  bias = True, learning_rate = 0.1, pop_size=pop, mutation_prob=mutation,\n","                                  curve = False, random_state=42)\n","        start_time = time.time()\n","        clf.fit(train_features, train_labels_onehot)\n","        end_time = time.time()\n","        ga_time = end_time-start_time\n","        y_pred = clf.predict(test_features)\n","        ga_score = metrics.accuracy_score(test_labels_onehot, y_pred)\n","\n","        results.append([pop, mutation, max_attempt, 'GA', ga_score, ga_time])\n","        print([pop, mutation, max_attempt, ga_score, ga_time])"],"metadata":{"id":"CP-lx4rQ2IWi"},"id":"CP-lx4rQ2IWi","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##########\n","#GA\n","##########\n","\n","clf = mlrose.NeuralNetwork(hidden_nodes=[100,100,50,50], activation='sigmoid',\n","                           algorithm = 'genetic_alg',early_stopping = False, \n","                           max_attempts = 100, max_iters = 500, clip_max = 5,\n","                           bias = True, learning_rate = 0.1, pop_size=500, mutation_prob=0.001,\n","                           curve = True, random_state=42)\n","start_time = time.time()\n","clf.fit(train_features, train_labels_onehot)\n","end_time = time.time()\n","ga_time = end_time-start_time\n","y_pred = clf.predict(test_features)\n","ga_score = metrics.accuracy_score(test_labels_onehot, y_pred)\n","ga_fitness_curve = clf.fitness_curve\n","\n","print('train time:', ga_time)\n","print('accuracy:', ga_score)"],"metadata":{"id":"HmtEb8dH0jm0"},"id":"HmtEb8dH0jm0","execution_count":null,"outputs":[]},{"cell_type":"code","source":["ga_fitness_curve = [ -x for x in ga_fitness_curve]\n","\n","plt.figure()\n","\n","plt.plot(ga_fitness_curve)\n","plt.xlabel(\"Iterations\")\n","plt.ylabel(\"Loss\")\n","plt.title('Loss curve for NN with GA')"],"metadata":{"id":"hbLoCQlmh6s_"},"id":"hbLoCQlmh6s_","execution_count":null,"outputs":[]},{"cell_type":"code","source":["ga_fitness_curve"],"metadata":{"id":"uApUOctw048d"},"id":"uApUOctw048d","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"name":"Assignment2_hyao66_partII.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":5}